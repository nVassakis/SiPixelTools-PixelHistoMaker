# Author Tiziano Bevilacqua (05/13/2022) 
# Script to submit Phase1PixelHistoMaker jobs to slurm, tested on PSI tier3 
# The script that is run in the jobs require a consistent amount of memory, a small number of input files per job is suggested

import re, os, sys, glob, time, logging, multiprocessing, socket, subprocess, shlex, getpass, math, shutil, ROOT
from optparse import OptionParser

# ---------------------- A few helping functions  ----------------------

def colored_text(txt, keys=[]):
    _tmp_out = ''
    for _i_tmp in keys:
        _tmp_out += '\033['+_i_tmp+'m'
    _tmp_out += txt
    if len(keys) > 0: _tmp_out += '\033[0m'

    return _tmp_out

def KILL(log):
    raise RuntimeError('\n '+colored_text('@@@ FATAL', ['1','91'])+' -- '+log+'\n')

def WARNING(log):
    print '\n '+colored_text('@@@ WARNING', ['1','93'])+' -- '+log+'\n'

def MKDIRP(dirpath, verbose=False, dry_run=False):
    if verbose: print '\033[1m'+'>'+'\033[0m'+' os.mkdirs("'+dirpath+'")'
    if dry_run: return
    try:
      os.makedirs(dirpath)
    except OSError:
      if not os.path.isdir(dirpath):
        raise
    return

def EXE(cmd, suspend=True, verbose=False, dry_run=False):
    if verbose: print '\033[1m'+'>'+'\033[0m'+' '+cmd
    if dry_run: return

    _exitcode = os.system(cmd)
    _exitcode = min(255, _exitcode)

    if _exitcode and suspend:
       raise RuntimeError(_exitcode)

    return _exitcode

#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
#- USAGE: --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
#- python my_batch_sub_script.py --taskname [taskname] --input [txt file with list of input files] --nfile [number of files per job] --prog [program to execute] --outdir [directory to save output to] --create -#
#- python my_batch_sub_script.py --taskname [taskname] --status --------------------------------------------------------------------------------------------------------------------------------------------------#
#- python my_batch_sub_script.py --taskname [taskname] --submit --------------------------------------------------------------------------------------------------------------------------------------------------#
#- python my_batch_sub_script.py --taskname [taskname] --resubmit ------------------------------------------------------------------------------------------------------------------------------------------------#
#- python my_batch_sub_script.py --taskname [taskname] --missing -------------------------------------------------------------------------------------------------------------------------------------------------#
#- python my_batch_sub_script.py --taskname [taskname] --hadd ----------------------------------------------------------------------------------------------------------------------------------------------------#
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#

# Read options from command line
usage = "Usage: python %prog filelists [options]"
parser = OptionParser(usage=usage)
parser.add_option("--slurm_file",  dest="job_template",type="string",       default="slurm_template.sh", help="Slurm job template")
parser.add_option("--input",       dest="input",       type="string",       default="",    help="input filelist")
parser.add_option("--nfile",       dest="NFILE",       type="int",          default=1,     help="Tells how many input files to run in a single job (Default=1)")
parser.add_option("--sleep",       dest="SLEEP",       type="int",          default=3,     help="Wait for this number of seconds between submitting each batch job (Default 3s)")
parser.add_option("--create",      dest="create",      action="store_true", default=False, help="create taskdir under PHM_PHASE1_out/ and prepare submission scripts, it divide the input filelist (provided with --input) according to the number of file for each job (specified with --nfile)")
parser.add_option("--submit",      dest="submit",      action="store_true", default=False, help="submit jobs from task")
parser.add_option("--resubmit",    dest="resubmit",    action="store_true", default=False, help="prepare resubmit script with missing jobs")
parser.add_option("--status",      dest="status",      action="store_true", default=False, help="check status of submitted jobs (R, PD, Completed")
parser.add_option("--missing",     dest="missing",     action="store_true", default=False, help="look for missing jobs")
parser.add_option("--hadd",        dest="hadd",        action="store_true", default=False, help="Submit hadding job")
parser.add_option("--step_two",    dest="step_2",      action="store_true", default=False, help="Option to merge merged outputs")
parser.add_option("--debug",       dest="debug",       action="store_true", default=False, help="Debug verbosity and skip removing of some intermediate files")
parser.add_option("--outdir",      dest="OUTDIR",      type="string",       default="/pnfs/psi.ch/cms/trivcat/store/user/bevila_t/test2/phys/xpluscharm/pixeltest", help="Output directory (Default: pnfs/.../pxeltest)")
parser.add_option("--taskname",    dest="TASKNAME",    type="string",       default="HISTO_MAKER_DEFAULT", help="Output directory (Default: HISTO_MAKER_DEFAULT)")
parser.add_option("--prog",        dest="PROG",        type="string",       default="Phase1PixelHistoMaker", help="The main program to run")
(opt,args) = parser.parse_args()

# --------------------- Proxy check ----------------------

os.system("voms-proxy-info --timeleft > proxy.txt")
with open('proxy.txt') as proxyfile:
    lines = proxyfile.readlines()
    if len(lines)==1:
        if not "Proxy not found" in lines[0]:
            timeleft = int(lines[0])
os.remove('proxy.txt')
if timeleft<172800:
    print "-"*60
    print "New proxy needed"
    print "suggest to use: voms-proxy-init -voms cms -valid 168:00"
    print "-"*60
    raise RuntimeError("PROXY ERROR")
else:
    print "-"*60
    print "Current proxy is long enough"
    print "-"*60

# ----------------------  Settings -----------------------
# Some further (usually) fixed settings, should edit them in this file

# Output directories/files
SUBTIME = time.strftime("%Y_%m_%d_%Hh%Mm%S", time.localtime())
if opt.OUTDIR == "":
    KILL("no output directory specified")

# Working directory, during running we cd here and back
OUT_PATH = opt.OUTDIR#+"/PixelHistoMaker"
EXEC_PATH = "../PHM_PHASE1_out/"+opt.TASKNAME

if opt.create:
    # Check input filelist
    if opt.input == "": KILL("no input filelist provided (--input files.txt)")
    # Summary file 
    os.system("echo \"process "+opt.TASKNAME+" summary\" > "+EXEC_PATH+"/summary.txt")
    os.system("echo \"\\n\" >> "+EXEC_PATH+"/summary.txt")


    # Create Task dir and copy input filelist and slurm template
    opt.input = os.path.abspath(opt.input)
    opt.job_template = os.path.abspath(opt.job_template)
    MKDIRP(EXEC_PATH+"/filelists")
    os.chdir(EXEC_PATH) 
    EXEC_PATH = os.getcwd()

    os.system("cp "+opt.input+" "+EXEC_PATH+"/all_input.txt")
    os.system("cp "+opt.job_template+" "+EXEC_PATH+"/slurm_jobscript.sh")

    # Summary file 
    os.system("echo \"Task name: "+opt.TASKNAME+"\" >> "+EXEC_PATH+"/summary.txt")
    os.system("echo \"Output dir: "+opt.OUTDIR+"\" >> "+EXEC_PATH+"/summary.txt")
    os.system("echo \"Input filelist: all_input.txt\" >> "+EXEC_PATH+"/summary.txt")
    os.system("echo \"Slurm jobs template: slurm_jobscript.sh\" >> "+EXEC_PATH+"/summary.txt")

    # Create filelist dir and filelists files to divide input files to jobs
    with open(opt.input) as fl:
        files = fl.readlines()
        njobs = len(files)/opt.NFILE
        print ("-"*60)
        print "number of jobs: "+str(njobs)
        print "total input files: "+str(len(files))

        # Summary file 
        os.system("echo \"Number of files per job: "+str(opt.NFILE)+"\" >> "+EXEC_PATH+"/summary.txt" )
        os.system("echo \"Number of jobs: "+str(njobs)+"\" >> "+EXEC_PATH+"/summary.txt")
        os.system("echo \"Total number of input files: "+str(len(files))+"\" >> "+EXEC_PATH+"/summary.txt")
        os.system("echo \"Program to run: "+opt.PROG+"\" >> "+EXEC_PATH+"/summary.txt")

        for i, filename in enumerate(files):
            idx = int(i/opt.NFILE)
            ash = int(100.0/(njobs)*idx)
            space = int(100.0/(njobs)*(njobs-idx))
            print "preparing file lists ["+"#"*ash+" "*space+"]"+"  \r",
            sys.stdout.flush()
            EXE("echo "+filename[:-1]+" | awk '{ print $1 }' >> filelists/filelist_"+str(idx)+".txt")
        print "\nprepared "+str(njobs)+" temporary filelists at: "
        print os.getcwd()+"/filelists"
    
    # Prepare submission script with "sbatch [job name] [out-log] [out-err] slurm_jobscript.sh [stringa inutile] [job_label] [input_files_list] [output dir] [executable_name]  
    print ("")
    print "Job Script file: "+opt.job_template
    os.system("ls -l filelists | awk '{ print $NF }' | tail -n +2 | head -n -1 > filelists/job_list.txt")
    os.system("cat -n filelists/job_list.txt | awk '{ printf \"%.4d %s\\n\", $1, $2 }' | awk '{ print \"sbatch --job-name="+opt.TASKNAME+"_\"$1\" -o /work/%u/test/.slurm/%x_%A_\"$1\".out -e /work/%u/test/.slurm/%x_%A_\"$1\".err slurm_jobscript.sh "+opt.TASKNAME+"_JOB\"$1\" \"$1\" "+EXEC_PATH+"/filelists/\"$2\" "+OUT_PATH+"/"+opt.TASKNAME+" "+opt.PROG+"\"}' > alljobs.sh")
    os.system("head -1 alljobs.sh | sed \"s;0001;test;g;\" > test.sh")
    print 
    print "jobs prepared at:", os.getcwd() 
    print "as: alljobs.sh" 
    print "or test 1 job with: test.sh"
    print ("-"*60)

    print ("-"*60)

    # Option to submit jobs right away
    answ = raw_input("Do you want to directly submit the jobs to slurm (all jobs or 1 test job)? (y/n/test) \n")
    if str(answ) == "y":
        os.system("wc -l alljobs.sh | awk '{print \"submitting \"$1\" jobs from \"$2\" ...\"}'")
        EXE("sh alljobs.sh")   
    elif str(answ) == "test":
        os.system("wc -l test.sh | awk '{print \"submitting \"$1\" jobs from \"$2\" ...\"}'")
        EXE("sh test.sh") 
    print ("-"*60)

# Same as before, ask for submission of jobs
elif opt.submit:
    os.chdir(EXEC_PATH) 
    EXEC_PATH = os.getcwd()
    print ("-"*60)
    answ = raw_input("Do you want to directly submit the jobs to slurm (all jobs or 1 test job)? (y/n/test) \n")
    if str(answ) == "y":
        os.system("wc -l alljobs.sh | awk '{print \"submitting \"$1\" jobs from \"$2\" ...\"}'")
        EXE("sh alljobs.sh")   
    elif str(answ) == "test":
        os.system("wc -l test.sh | awk '{print \"submitting \"$1\" jobs from \"$2\" ...\"}'")
        EXE("sh test.sh") 
    print ("-"*60)
    
# Check the status of submitted jobs, it recover job info from summary file in the task directory 
# and query squeue for pending and running jobs. Then check the output dir to look for completed jobs.
elif opt.status:
    print ("-"*60)
    with open(EXEC_PATH+"/summary.txt") as fl:
        lines = fl.readlines()
        for line in lines:
            fields = re.split(": |\n", line)
            if fields[0] == "Number of jobs":
                njobs = int(fields[1])
            elif fields[0] == "Task name":
                TASKNAME = fields[1]
            elif fields[0] == "Output dir":
                OUT_PATH = fields[1]
                
    os.system("( squeue -n `cat "+EXEC_PATH+"/alljobs.sh | awk '{print $2}' | sed 's;--job-name=;;g;' | sed ':label1 ; N ; $! b label1;s;\\n;,;g'` > taskjobs ) > /dev/null")
    os.system("grep PD taskjobs > Pending")
    os.system("grep \" R \" taskjobs > Running")
    os.system("( ls "+OUT_PATH+"/"+TASKNAME+" | grep .root > Completed ) >  /dev/null")
    os.system("sort -u Completed > Comp")
    os.system("mv Comp Completed")
    os.system("ls -l "+OUT_PATH+"/"+TASKNAME+"/logs | grep -v test | grep .out > Done")
    os.system("echo \"Status of Task "+TASKNAME+": ("+str(njobs)+" Jobs)\"")
    os.system("echo \"Jobs - Pending                : `wc -l Pending | awk '{ print $1}'`\"")
    os.system("echo \"     - Running                : `wc -l Running | awk '{ print $1}'`\"")
    os.system("echo \"     - Done (with STDOUT)     : `wc -l Done | awk '{ print $1}'`\"")
    os.system("echo \"------------------------------------\"")
    os.system("echo \"     - Completed (has output) : `wc -l Completed | awk '{ print $1}'`\"")
    os.system("rm taskjobs Pending Running Completed Done")
    print ("-"*60)
    
# Look for finished jobs and then prints number of jobs that are not in the output dir
elif opt.missing:
    print ("-"*60)
    with open(EXEC_PATH+"/summary.txt") as fl:
        lines = fl.readlines()
        for line in lines:
            fields = re.split(": |\n", line)
            if fields[0] == "Number of jobs":
                njobs = int(fields[1])
            elif fields[0] == "Task name":
                TASKNAME = fields[1]
            elif fields[0] == "Output dir":
                OUT_PATH = fields[1]

    os.system("ls "+OUT_PATH+"/"+TASKNAME+" | grep .root >> output")
    os.system("cat output | sort -u | sed 's;_; ;g;s;\.; ;g' | awk '{ printf \"%d\\n\", $(NF-1) }' > jobnums")
    os.system("seq 1 "+str(njobs)+" > Seq")
    os.system("diff Seq jobnums | grep \"<\" | awk '{ printf \"%d,\", $2 }' | sed 's;,$;\\n;'")
    os.system("rm Seq jobnums output")
    print ("-"*60)

# same as missing option but also prepare a resubmission script for such jobs
elif opt.resubmit:
    print ("-"*60)
    with open(EXEC_PATH+"/summary.txt") as fl:
        lines = fl.readlines()
        for line in lines:
            fields = re.split(": |\n", line)
            if fields[0] == "Number of jobs":
                njobs = int(fields[1])
            elif fields[0] == "Task name":
                TASKNAME = fields[1]
            elif fields[0] == "Output dir":
                OUT_PATH = fields[1]

    os.system("ls "+OUT_PATH+"/"+TASKNAME+" | grep .root >> output")
    os.system("cat output | sort -u | sed 's;_; ;g;s;\.; ;g' | awk '{ printf \"%d\\n\", $(NF-1) }' > jobnums")
    os.system("seq 1 "+str(njobs)+" > Seq")
    os.system("diff Seq jobnums | grep \"<\" | awk '{ printf \"%.4d,\", $2 }' | sed 's;,$;\\n;' > resubmit ")
    os.system("rm "+EXEC_PATH+"/resubmit.sh")
    with open("resubmit") as fl:
        files = fl.readlines()
        files = re.split(',|\n',files[0])
        for i,job in enumerate(files):
            if job == '': break
            idx = int(i/(float(len(files))/100))
            print "preparing resubmission jobs list ["+"#"*idx+" "*(100-idx)+"]"+"  \r",
            sys.stdout.flush()
            os.system("grep "+job+" "+EXEC_PATH+"/alljobs.sh >> "+EXEC_PATH+"/resubmit.sh")
    os.system("rm Seq jobnums output resubmit")
    print"\nDone: resubmit.sh file created at "+EXEC_PATH+"/resubmit.sh"
    print ("-"*60) 

# Submit hadd job for files in the output directory
elif opt.hadd:
    print ("-"*60)
    with open(EXEC_PATH+"/summary.txt") as fl:
        lines = fl.readlines()
        for line in lines:
            fields = re.split(": |\n", line)
            if fields[0] == "Number of jobs":
                njobs = int(fields[1])
            elif fields[0] == "Task name":
                TASKNAME = fields[1]
            elif fields[0] == "Output dir":
                OUT_PATH = fields[1]
            elif fields[0] == "Program to run":
                PROG = fields[1]

    os.chdir(EXEC_PATH) 
    EXEC_PATH = os.getcwd()
    nfile_pj = 10
    if opt.step_2:
        merged_dir = "/merged"
        merg = "merged | grep "  
        os.system("rm filelists/merging* ")
        njobs = int(njobs/10)
        nfile_pj = 5
    else:
        merg = ""  
        merged_dir = ""   
    if njobs > 10:
        os.system("ls -l "+OUT_PATH+"/"+TASKNAME+merged_dir+" | grep "+merg+".root | awk '{ print \"/\" $9}' | sed \"s:^:"+OUT_PATH+"/"+TASKNAME+merged_dir+":\" | sed \"s:/pnfs/psi.ch/cms/trivcat/:root\://cms-xrd-global.cern.ch//:\" > filelists/tmp")
    for i in range(int(njobs/nfile_pj)):
        os.system("tail -n "+str(nfile_pj)+" filelists/tmp > filelists/merging_"+str(i))
        os.system("head -n -"+str(nfile_pj)+" filelists/tmp > tmptmp")
        os.system("mv tmptmp filelists/tmp")
    os.system("rm filelists/tmp")

    os.system("ls -l filelists | grep merging | awk '{ print $NF }' > filelists/merging_job_list.txt")
                                           #$1              $2      $3      $4     $5       $6
    #sbatch jobname .out .log slurm.sh jobname(redundant) job_ID filelist outdir program --hadd
    os.system("cat -n filelists/merging_job_list.txt | awk '{ printf \"%.4d %s\\n\", $1, $2 }' | awk '{ print \"sbatch --job-name="+TASKNAME+"_MERGING_\"$1\" -o /work/%u/test/.slurm/%x_%A_\"$1\".out -e /work/%u/test/.slurm/%x_%A_\"$1\".err slurm_jobscript.sh "+TASKNAME+"_JOBMERGING\"$1\" \"$1\" "+EXEC_PATH+"/filelists/\"$2\" "+OUT_PATH+"/"+TASKNAME+merged_dir+" "+PROG+" --hadd\"}' > merging_alljobs.sh")
    os.system("head -1 merging_alljobs.sh | sed \"s;0001;test;g;\" > merging_test.sh")
    
    answ = raw_input("Do you want to directly submit the jobs to slurm (all jobs or 1 test job)? (y/n/test) \n")
    if str(answ) == "y":
        os.system("wc -l merging_alljobs.sh | awk '{print \"submitting \"$1\" jobs from \"$2\" ...\"}'")
        EXE("sh merging_alljobs.sh")   
        os.system("wc -l merging_alljobs.sh | awk '{print \"submitted \"$1\" jobs from \"$2\" ...\"}'")
    elif str(answ) == "test":
        os.system("wc -l merging_test.sh | awk '{print \"submitting \"$1\" jobs from \"$2\" ...\"}'")
        EXE("sh merging_test.sh") 

    if not opt.debug:
        os.system("rm filelists/merging_job_list.txt")
        #os.system("rm filelists/merging*")

    print ("-"*60)

    #print "submitting merging job..."
    #os.chdir(EXEC_PATH) 
    #os.system("sbatch --job-name="+TASKNAME+"_MERGING -o /work/%u/test/.slurm/%x_%A_MERGING.out -e /work/%u/test/.slurm/%x_%A_MERGING.err slurm_jobscript.sh "+TASKNAME+"_JOBMERGING MERGING "+EXEC_PATH+"/filelists/dummystring "+OUT_PATH+"/"+TASKNAME+" "+PROG+" --hadd")
    #print ("-"*60)
